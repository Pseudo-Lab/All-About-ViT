# Q&A

## T2T-ViT-14랑 DN Structure에 있는 T2T-ViT-14를 동일한 모델로 봐야하나요?

Tokens-to-Token 논문의 Table 7에서  Ablation type에 따라 실험한 결과를 보여주는데요. T2T module에 있는 T2T-ViT-14랑 DN Structure에 있는 T2T-ViT-14를 동일한 모델로 봐야하나요? DN structure에 있는 T2T-ViT-14는 deep-narrow 구조가 적용돼서 params, MACs가 좀 달라질 거 같은데 T2T module에 있는 T2T-ViT-14랑 정확히 일치해서 같은 모델인건지 다른 모델인건지 헷갈리네요..

>제 생각에는 T2T module과 DN structure에 있는 T2T-ViT-14은 같은 모델이고 deep-narrow 구조이기 때문에 shallow-wide 구조를 적용한 T2T-ViT-d768-4와 비교한 내용같습니다.
>

## Soft Split을 할 때 locality inductive bias를 부여한다고 봐도 될까요?

T2T module에서 SS를 할 때 정보손실을 막기 위해 patch를 overlapping 하면서 unfold 한다고 했는데 token 정보 수준에서 correlation을 높여주면서 locality inductive bias를 부여한다고 봐도 될까요? 전체적으로 CNN을 많이 차용하는게 단순히 정보손실을 피하기 위함이 아닌 것 같은 느낌이 드네요.

>아 저도 introduction에서 말한 vit 문제점(데이터가 많아야한다, local structure를 못본다)을 해결하기위해  locality inductive bias를 부여하는 방향으로 개선했다고 이해했어요
>

[Reference]

- Unfold 관련
    - https://stackoverflow.com/questions/53972159/how-does-pytorchs-fold-and-unfold-work
https://www.facebook.com/groups/PyTorchKR/posts/1685133764959631/
- SE module 관련
    - https://github.com/yitu-opensource/T2T-ViT/blob/0f63dc9558f4d192de926504dbddfa1b3f5db6ca/models/t2t_vit_se.py

- performer 관련
    - https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html 

---
  
Edit by `김주영`