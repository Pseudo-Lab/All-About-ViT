
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Compact Convolutional Transformers &#8212; Vision Transformer의 모든 것</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/PseudoLab_logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Compact Convolutional Transformers Code" href="08_code.html" />
    <link rel="prev" title="Compact Convolutional Transformers" href="08_List.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/PseudoLab_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Vision Transformer의 모든 것</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Vision Transformer의 모든 것
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inductive Bias와 Self-Attention
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch1/01_List.html">
   Inductive Bias와 Self-Attention
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/Inductive_Bias.html">
     Inductive Bias
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/Self-Attention.html">
     Self-Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_code.html">
     Self-Attention Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Vision Transformer
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch2/02_List.html">
   Vision Transformer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/vit.html">
     Vision Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_code.html">
     Vision Transformer Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pyramid Vision Transformer
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch3/03_List.html">
   Pyramid Vision Transformer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/Pyramid_Vision_Transformer.html">
     Pyramid Vision Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/03_code.html">
     Pyramid Vision Transformer Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/03_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DeiT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/04_List.html">
   DeiT
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/DeiT.html">
     DeiT: Training data-efficient image transformers &amp; distillation through attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_code.html">
     DeiT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tokens-to-Token ViT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch5/05_List.html">
   Tokens-to-Token ViT
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/T2T-ViT.html">
     Tokens-to-Token ViT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/05_code.html">
     Tokens-to-Token ViT Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/05_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BEiT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch6/06_List.html">
   BEiT: BERT Pre-Training of Image Transformers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/BEiT.html">
     BEiT: BERT Pre-Training of Image Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/06_code.html">
     BEiT: BERT Pre-Training of Image Transformers Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/06_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SepViT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/07_List.html">
   SepViT: Separable Vison Transformer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/SepViT.html">
     SepViT: Separable Vison Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/07_code.html">
     SepViT: Separable Vison Transformer Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/07_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Compact Convolutional Transformers
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="08_List.html">
   Compact Convolutional Transformers
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Compact Convolutional Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_code.html">
     Compact Convolutional Transformers Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Compact Vision Transformers
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch9/09_List.html">
   Compact Vision Transformers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/CvT.html">
     Compact Vision Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch9/09_code.html">
     Compact Vision Transformers Code
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Swin Transformer
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch10/10_List.html">
   Swin Transformer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/Swin_Transformer.html">
     Swin Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/10_code.html">
     Swin Transformer Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch10/10_qa.html">
     Q&amp;A
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Vision Transformer with Deformable Attention
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch11/11_List.html">
   Vision Transformer with Deformable Attention
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch11/Vision_Transformer_with_Deformable_Attention.html">
     Vision Transformer with Deformable Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch11/11_code.html">
     Vision Transformer with Deformable Attention Code
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Mobile Vision Transformer
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch12/12_List.html">
   Mobile VisionTransformers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/MobileViT_v1.html">
     MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/12_v1_code.html">
     MobileViT V1 Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/MobileViT_v2.html">
     Separable Self-attention for Mobile VisionTransformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/12_v2_code.html">
     MobileViT V2 Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/MobileViT_v3.html">
     MobileViTv3: Mobile-Friendly Vision Transformer with Simple and Effective Fusion of Local, Global and Input Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch12/12_v3_code.html">
     MobileViT V3 Code
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pseudo-lab/All-About-ViT"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pseudo-lab/All-About-ViT/issues/new?title=Issue%20on%20page%20%2Fdocs/ch8/CCT.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/docs/ch8/CCT.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-interaction">
     1. sparse interaction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-share">
     2. parameter share
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-representations">
     3. equivariant representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#method">
   Method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformer-based-backbone">
     Transformer-based Backbone
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#small-and-compact-models">
     Small and Compact Models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seqpool">
     SeqPool
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-tokenizer">
     Convolutional Tokenizer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experiments">
   Experiments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Compact Convolutional Transformers</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-interaction">
     1. sparse interaction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-share">
     2. parameter share
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-representations">
     3. equivariant representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#method">
   Method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformer-based-backbone">
     Transformer-based Backbone
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#small-and-compact-models">
     Small and Compact Models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seqpool">
     SeqPool
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-tokenizer">
     Convolutional Tokenizer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experiments">
   Experiments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="compact-convolutional-transformers">
<h1>Compact Convolutional Transformers<a class="headerlink" href="#compact-convolutional-transformers" title="Permalink to this headline">#</a></h1>
<p><img alt="https://k.kakaocdn.net/dn/dfX6w2/btrP3Adw0q0/VOkDfDn9L7UJXJXb5KkmC0/img.png" src="https://k.kakaocdn.net/dn/dfX6w2/btrP3Adw0q0/VOkDfDn9L7UJXJXb5KkmC0/img.png" /></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<p>Convolution의 중요한 개념으로 다음 세 가지를 말할 수 있다.</p>
<ul class="simple">
<li><p>sparse interaction</p></li>
<li><p>weight sharing</p></li>
<li><p>equivariant representations</p></li>
</ul>
<p>각각의 개념들에 대해서 리마인드해보자.</p>
<section id="sparse-interaction">
<h3>1. sparse interaction<a class="headerlink" href="#sparse-interaction" title="Permalink to this headline">#</a></h3>
<p><img alt="https://k.kakaocdn.net/dn/7PQFM/btrP2oSeIEQ/bCSlkHHItpoaguDWkNA82K/img.png" src="https://k.kakaocdn.net/dn/7PQFM/btrP2oSeIEQ/bCSlkHHItpoaguDWkNA82K/img.png" /></p>
<p>sparse interaction은 위 그림의 윗부분처럼 이전 layer의 output이 다음 layer의 input이 될 때 fully connected가 아니라 일부만 연결이 되어서 유의미한 feature만 찾을 수 있는 것을 말한다.</p>
</section>
<section id="parameter-share">
<h3>2. parameter share<a class="headerlink" href="#parameter-share" title="Permalink to this headline">#</a></h3>
<p>sparse interaction에서 그림의 아래부분처럼  파라미터를 공유하지 않을 경우 input의 하나하나 모두 연결되어 전체적으로 데이터를 한 번에 본다. 하지만 윗부분처럼 파라미터를 공유할 경우 필터 하나가 input의 여러 곳을 보기 때문에 데이터를 더 효율적으로 볼 수 있다. (여기서 파라미터를 공유한다는 의미는 필터 하나로 공유한다는 말이다.) 이 때문에 이미지 내의 객체가 어디에 있든 찾을 수 있다.</p>
</section>
<section id="equivariant-representations">
<h3>3. equivariant representations<a class="headerlink" href="#equivariant-representations" title="Permalink to this headline">#</a></h3>
<p>간단히 말해서 input이 바뀌면 ouput도 바뀐다는 것을 의미한다. 예를 들어서 input 이미지에서 객체의 위치가 변하면 output도 동일하게 변한다는 것이다.</p>
<p>invariance 특성과 헷갈릴 수 있는데 invariance의 경우 FC 레이어(또는 pooling)를 통해 나온 output이 input 이미지에서 객체의 위치가 변해도 동일하다는 것을 의미한다.</p>
<p>정리하면 equivariant는 input의 위치 정보가 변하면 output의 위치 정보도 변해야 한다는 것을 의미하고 invariance는 input의 위치 정보가 변해도 output의 classification 결과는 동일해야한다는 것을 의미한다.</p>
<blockquote>
<div><p>“Transformers lack some of the inductive biases inherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well when trained on insufficient amounts of data.”</p>
</div></blockquote>
<p>ViT의 저자는 위와 같이 주장한다. 즉, Transformer는 CNN과 달리 많은 양의 데이터가 필요하다는 얘기이다.</p>
<p>본 논문에서는 CNN, Transformer 두 개의 갭을 채우기위해 sparse interaction과 weight sharing 특성을 가지면서 중요한 feature를 볼 수 있는 architecture를 개발한다.</p>
<p>바로 ViT보다 더 작고 compact한 버전인 ViT-Lite를 소개하며 CIFAR-10 데이터셋에서 90% 정확도를 가진다. 그리고 sequence pooling를 적용하고 CVT(Compact Vision Transformer)로 ViT-Lite를 확장한다. 또한 tokenization 단계에 convolutional block을 추가하고 CCT(Compact Convolutional Transformer)를 만든다. 이렇게 추가하여 CIFAR-10 데이터셋에서 98% 정확도에 도달하였다. 그리고 DeiT와 같은 비슷한 크기의 모델보다 더 나은 성능을 보였다고 한다.</p>
<blockquote>
<div><p>Can vision transformers be trained from scratch on small datasets?</p>
</div></blockquote>
</section>
</section>
<section id="method">
<h2>Method<a class="headerlink" href="#method" title="Permalink to this headline">#</a></h2>
<p><img alt="https://k.kakaocdn.net/dn/cuh3G8/btrP7UCRmJa/NS0qKjlDKtpnOPD6a5Mim1/img.png" src="https://k.kakaocdn.net/dn/cuh3G8/btrP7UCRmJa/NS0qKjlDKtpnOPD6a5Mim1/img.png" /></p>
<p>본 논문에서는 세 가지의 모델을 제안한다.</p>
<ul class="simple">
<li><p><strong>ViT-Lite</strong></p></li>
</ul>
<p>ViT-Lite는 본래 ViT 구조와 거의 같지만 small-scale learning에 적합한 크기를 가진다.</p>
<ul class="simple">
<li><p><strong>Compact Vision Transformers (CVT)</strong></p></li>
</ul>
<p>CVT는 SeqPool을 사용하여 전체 sequence를 pool한다. 따라서 SeqPool은 [class] 토큰을 대체할 수 있다.</p>
<ul class="simple">
<li><p><strong>Compact Convolutional Transformers (CCT)</strong></p></li>
</ul>
<p>CCT는 convolutional tokenizer를 활용하여 더 풍부한 token을 생성하고 local 정보를 유지한다. convolutional tokenizer는 ViT와 비교하여 patch들끼리의 관계를 더 잘 학습할 수 있게한다.</p>
<section id="transformer-based-backbone">
<h3>Transformer-based Backbone<a class="headerlink" href="#transformer-based-backbone" title="Permalink to this headline">#</a></h3>
<p>encoder는 transformer block으로 구성되어있으며 각각 MHSA, MLP block이 포함된다. 또한 Layer Normalization, GELU, dropout을 적용한다. Positional embedding은 learnable 또는 sinusoidal을 사용할 수 있고 둘 다 효과적인 성능을 보인다.</p>
</section>
<section id="small-and-compact-models">
<h3>Small and Compact Models<a class="headerlink" href="#small-and-compact-models" title="Permalink to this headline">#</a></h3>
<p>ViT 구조 중 가장 작은 ViT-Base는 12개의 attention head를 가지는 12 layer transformer encoder를 포함하고 head당 64 dimension, MLP block에서는 2048 dimensional hidden layer를 포함한다. 16x16 크기의 patch size를 가지고 85M 파라미터를 가진다.</p>
<p>하지만 본 논문의 저자는 2 layers, 2heads, 128 dimensional hidden layer 구조를 제안한다. 다음 표를 보면 어떻게 backbone 구조를 변형했는지 알 수 있고 가장 작은 모델(CCT-2)은 0.22M 파라미터를 가지고 가장 큰 것 (CCT-14일 것 같음)은 3.8M 파라미터를 가진다고 한다.</p>
<p><img alt="https://k.kakaocdn.net/dn/bMUjw8/btrP6ccR0KN/Pk2MLyz2NfWKkMM9tUkHdk/img.png" src="https://k.kakaocdn.net/dn/bMUjw8/btrP6ccR0KN/Pk2MLyz2NfWKkMM9tUkHdk/img.png" /></p>
<p>또한 데이터셋에 따라 patch size를 다음과 같이 변형했다고 한다.</p>
<p><img alt="https://k.kakaocdn.net/dn/bhQ8Lv/btrP9HCBb8l/hKvVYe3NjJPWsUbBk9zXp0/img.png" src="https://k.kakaocdn.net/dn/bhQ8Lv/btrP9HCBb8l/hKvVYe3NjJPWsUbBk9zXp0/img.png" /></p>
</section>
<section id="seqpool">
<h3>SeqPool<a class="headerlink" href="#seqpool" title="Permalink to this headline">#</a></h3>
<p>output sequence token들을 pooling하는 attention 기반 method, SeqPool을 제안한다. motivation은 ouput sequence에 input 이미지의 각 다른 부분들끼리의 관계 정보를 포함하는 것이다. 이 정보는 성능을 향상시켜줄 것이고 learnable token과 비교해서 추가적인 파라미터가 없다. 또란 이러한 변화는 더 적은 token을 가지고 학습하기 때문에 연산량이 약간 줄어든다.</p>
<p>Linear 레이어를 통해 output sequence를 다음과 같이 매핑한다.</p>
<p><img alt="https://k.kakaocdn.net/dn/w6dUn/btrP6hZBOu9/KwALbQcXrUkbHUlQ63Qh9k/img.png" src="https://k.kakaocdn.net/dn/w6dUn/btrP6hZBOu9/KwALbQcXrUkbHUlQ63Qh9k/img.png" /></p>
<p><img alt="https://k.kakaocdn.net/dn/MaQig/btrP4W9ozDa/AymkKhmLfCf31RgSpjECpK/img.png" src="https://k.kakaocdn.net/dn/MaQig/btrP4W9ozDa/AymkKhmLfCf31RgSpjECpK/img.png" /></p>
<ul class="simple">
<li><p>XLXL: L 번째 layer의 transformer encoder ff의 output</p></li>
<li><p>bb: batch size</p></li>
<li><p>nn: sequence length</p></li>
<li><p>d: total embedding dimension</p></li>
</ul>
<p>XLXL은 다시 linear 레이어 g(XL)∈Rd×1g(XL)∈Rd×1 에 들어가고 softmax를 통과한다.</p>
<p><img alt="https://k.kakaocdn.net/dn/v0T4D/btrP5Fl6021/suH5Ig3GyLnJKoFARjTbGk/img.png" src="https://k.kakaocdn.net/dn/v0T4D/btrP5Fl6021/suH5Ig3GyLnJKoFARjTbGk/img.png" /></p>
<p>그리고 X‘LX‘L과 XLXL의 행렬곱을 해서 중요한 가중치를 얻는다.</p>
<p><img alt="https://k.kakaocdn.net/dn/dQWNIP/btrP91nqPCJ/NjmBUtcJiC4J852Vi3kGM0/img.png" src="https://k.kakaocdn.net/dn/dQWNIP/btrP91nqPCJ/NjmBUtcJiC4J852Vi3kGM0/img.png" /></p>
<p>마지막으로 flatten을 하고 classifier에 넣어준다.</p>
<p>learnable, statick method 포함 여러 pooling method로 실험을 해보았는데 learnable pooling이 가장 좋은 성능을 보였다고 한다. 저자는 그 이유가 각 embedding된 patch는 같은 양의 entropy(정보)를 가지고 있지 않기 때문이라고 한다. 또한 sequence pooling은 공간적으로 sparse한 데이터 간의 정보를 더 잘 활용할 수 있게 해준다고 한다.</p>
</section>
<section id="convolutional-tokenizer">
<h3>Convolutional Tokenizer<a class="headerlink" href="#convolutional-tokenizer" title="Permalink to this headline">#</a></h3>
<p>모델에 inductive bias를 집어넣기위해 ViT-Lite와 CVT에서 embedding과 patch를 convolutional block으로 바꾼다. 이 block은 하나의 convolution과 ReLU, max pool로 구성되어있다. 이미지 또는 feature map이 주어진다면 다음과 같은 수식이 적용될 것이다.</p>
<p><img alt="https://k.kakaocdn.net/dn/Ma3Lj/btrP80pdWUm/Yy8nItocqgy5QOnK8mD7KK/img.png" src="https://k.kakaocdn.net/dn/Ma3Lj/btrP80pdWUm/Yy8nItocqgy5QOnK8mD7KK/img.png" /></p>
<p>convolution과 max pool은 overlapping할 수 있으며 inductive bias 주입을 통해 성능을 향상시킬 수 있다. 또한 지역적인 공간 정보를 유지할 수 있게 해준다. 추가로 convolutional block을 사용함으로써 ViT와 같은 모델에 유연하게 붙일 수 있다. 더 이상 이미지 해상도에 따른 patch size를 나눠야할 필요가 없어진다.</p>
<p>convolution으로 이미지를 embedding해서 더 효율적으로 더 풍부한 토큰을 만들 수 있을 것이라고 생각한다고 한다. 이 block은 kernel size, stride, padding으로 downsampling ratio를 조정할 수 있고 반복적으로 downsampling할 수도 있다. self-attention은 token 개수에 따라 quadratic한 시간, 공간 복잡도를 가지고 token의 개수는 input feature map의 해상도와 동일하다 그래서 downsampling을 한 결과에서는 더 적은 token을 가지므로 훨씬 연산량이 감소한다. 그리고 이러한 tokenization은 positional embedding이 따로 없어도 될 정도로 좋은 유연성을 가진다.</p>
</section>
</section>
<section id="experiments">
<h2>Experiments<a class="headerlink" href="#experiments" title="Permalink to this headline">#</a></h2>
<p><img alt="https://k.kakaocdn.net/dn/bNIcif/btrP8ZjAaN6/hPqXRtIZ2gj1oGdu1lmaK0/img.png" src="https://k.kakaocdn.net/dn/bNIcif/btrP8ZjAaN6/hPqXRtIZ2gj1oGdu1lmaK0/img.png" /></p>
<p><img alt="https://k.kakaocdn.net/dn/ujKGP/btrP8ZKGaZR/rShGVT4TCoO3ms11BTmIA1/img.png" src="https://k.kakaocdn.net/dn/ujKGP/btrP8ZKGaZR/rShGVT4TCoO3ms11BTmIA1/img.png" /></p>
<p>한 가지 의문이 드는 점은 5000 epoch 학습하여 가장 좋은 성능을 얻었다고 했는데 과연 5000 epoch 학습하는 것이 효율적인 학습이라고 할 수 있을까하는 것이다.</p>
<hr class="docutils" />
<p>Author by <code class="docutils literal notranslate"><span class="pre">김주영</span></code><br />
Edit by <code class="docutils literal notranslate"><span class="pre">김주영</span></code></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/ch8"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="08_List.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Compact Convolutional Transformers</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="08_code.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compact Convolutional Transformers Code</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By PseudoLab<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>